{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum model\n",
    "\n",
    "The fair model is designed from the data set that was made in the data analysis section and his can compare with the classical fair model, for this will be with the use of neural networks to predict when there is a backorder and thus pass the data to the company responsible for the distribution and storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callign the dependencies fro mpennylane the optimizers, and methods to generate a quantum circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cK5Ry9dADtir",
    "outputId": "b438ff3d-7cc8-45f8-e3db-1d436e81c1c6"
   },
   "outputs": [],
   "source": [
    "#improt pennylane dependnecies\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "\n",
    "\n",
    "# load the csv files\n",
    "import pandas as pd\n",
    "\n",
    "# plot the historical acc and cost\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=False)\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and test sets from the Data analysis module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZTdT7iH2DpUG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((2000, 16), (2000,)), ((6159, 16), (6159,)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"fair_train.csv\")\n",
    "X_train,y_train = data_train[data_train.columns[:16]].values, data_train[data_train.columns[16]].values\n",
    "\n",
    "data_test = pd.read_csv(\"classic_test.csv\")\n",
    "X_test,y_test = data_test[data_test.columns[:16]].values, data_test[data_test.columns[16]].values\n",
    "\n",
    "(X_train.shape, y_train.shape),(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init the device that called the backend default.qubit and using 4 qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s804AwFCEFV8"
   },
   "outputs": [],
   "source": [
    "n_wires = 4\n",
    "dev = qml.device(\"default.qubit\", wires=n_wires)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the structure of the entenglament for MERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(weights, wires):\n",
    "    qml.CNOT(wires=[wires[0],wires[1]])\n",
    "    qml.RY(weights[0], wires=wires[0])\n",
    "    qml.RY(weights[1], wires=wires[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters for MERA quantum circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_block_wires = 2\n",
    "n_params_block = 2\n",
    "n_blocks = qml.MERA.get_n_blocks(range(n_wires),n_block_wires)\n",
    "n_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Called the quantum circuit for all the data train using amplitude embedding, where the  data is encoded into the amplitudes of a quantum state. A normalized classical $N$ -dimensional datapoint $x$ is represented by the amplitudes of a $n$-qubit quantum state $\\left|\\psi_{x}\\right\\rangle$ as\n",
    "$$\n",
    "\\left|\\psi_{x}\\right\\rangle=\\sum_{i=1}^{N} x_{i}|i\\rangle\n",
    "$$\n",
    "where $N=2^{n}, x_{i}$ is the $i$-th element of $x$, and $|i\\rangle$ is the $i$-th computational basis state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "P2gS_r0dEN5s"
   },
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "\n",
    "    qml.AmplitudeEmbedding(x, wires=[0,1,2,3],normalize=True,pad_with=True)\n",
    "\n",
    "    for w in weights:\n",
    "\n",
    "        qml.MERA(range(n_wires),n_block_wires,block, n_params_block, w)\n",
    "        #print(w)\n",
    "    #print(x)\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xLSeVH8CEPUi"
   },
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def cost(weights, bias, X, Y):\n",
    "    #print(1)\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFN174tZEU22",
    "outputId": "7de4359e-7953-487e-8f08-30a7623d639e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 11.08386778   2.51426189]\n",
      "  [  6.14959212  14.07994722]\n",
      "  [ 11.73421292  -6.14041802]\n",
      "  [  5.96958159  -0.95100539]\n",
      "  [ -0.64854317   2.57986647]]\n",
      "\n",
      " [[  0.90505245   9.13746993]\n",
      "  [  4.78174105   0.76450668]\n",
      "  [  2.78887494   2.09653763]\n",
      "  [  9.38757568  -1.28904739]\n",
      "  [  1.96706238  -5.3664418 ]]\n",
      "\n",
      " [[-16.0409081    4.10680676]\n",
      "  [  5.43141282  -4.66316035]\n",
      "  [ 14.2612889   -9.13804904]\n",
      "  [  0.28750924  -1.17611082]\n",
      "  [  9.63073584   9.23225343]]\n",
      "\n",
      " [[  0.97356339   2.37606519]\n",
      "  [ -5.57812237 -12.44571127]\n",
      "  [ -2.1859965    0.98236955]\n",
      "  [  7.73014433   7.5547754 ]\n",
      "  [ -2.43364617  -1.8994242 ]]] 0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "num_layers = 4\n",
    "weights_init = 2*np.pi * np.random.randn(num_layers,n_blocks, n_params_block, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭QubitStateVector(M0)─╭X──RY(2.51)────────────────╭●──RY(5.97)──╭●──RY(-0.65)─╭X──RY(9.14)───\n",
      "1: ─├QubitStateVector(M0)─╰●──RY(11.08)─╭X──RY(-6.14)─│─────────────╰X──RY(2.58)──╰●──RY(0.91)─╭X\n",
      "2: ─├QubitStateVector(M0)─╭●──RY(6.15)──│─────────────╰X──RY(-0.95)─╭●──RY(4.78)───────────────│─\n",
      "3: ─╰QubitStateVector(M0)─╰X──RY(14.08)─╰●──RY(11.73)───────────────╰X──RY(0.76)───────────────╰●\n",
      "\n",
      "────────────╭●──RY(9.39)──╭●──RY(1.97)──╭X──RY(4.11)─────────────────╭●──RY(0.29)──╭●──RY(9.63)───╭X\n",
      "───RY(2.10)─│─────────────╰X──RY(-5.37)─╰●──RY(-16.04)─╭X──RY(-9.14)─│─────────────╰X──RY(9.23)───╰●\n",
      "────────────╰X──RY(-1.29)─╭●──RY(5.43)─────────────────│─────────────╰X──RY(-1.18)─╭●──RY(-5.58)────\n",
      "───RY(2.79)───────────────╰X──RY(-4.66)────────────────╰●──RY(14.26)───────────────╰X──RY(-12.45)───\n",
      "\n",
      "───RY(2.38)───────────────╭●──RY(7.73)─╭●──RY(-2.43)─┤     \n",
      "───RY(0.97)─╭X──RY(0.98)──│────────────╰X──RY(-1.90)─┤  <Z>\n",
      "────────────│─────────────╰X──RY(7.55)───────────────┤     \n",
      "────────────╰●──RY(-2.19)────────────────────────────┤     \n"
     ]
    }
   ],
   "source": [
    " print(qml.draw(circuit,expansion_strategy='device',wire_order=[0,1,2,3])(weights_init,np.asarray(X_train[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2IhcVFlEV_V",
    "outputId": "3b78e6fc-f121-4095-a4b3-47e1b07ce621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.08386778  2.51426189]\n",
      "[0.90505245 9.13746993]\n",
      "[-16.0409081    4.10680676]\n",
      "[0.97356339 2.37606519]\n"
     ]
    }
   ],
   "source": [
    "for i in weights_init:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1WEWkuIOEXnm"
   },
   "outputs": [],
   "source": [
    "y_train = np.where(y_train < 1, -1, y_train)\n",
    "y_test = np.where(y_test < 1, -1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Vrs1X5UiMnWJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X,y = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8Z8HLOXEY1n",
    "outputId": "249d3445-bac4-4885-8c86-49053fd8b78a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "opt = NesterovMomentumOptimizer(0.4)\n",
    "batch_size = 32\n",
    "\n",
    "num_data = len(y_train)\n",
    "num_train = 0.9\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "print()\n",
    "\n",
    "cost_g = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "plt.show()\n",
    "for it in range(50):\n",
    "    X_train_70, X_test_30, y_train_70, y_test_30 =train_test_split(np.asarray(X), np.asarray(y), train_size=num_train, test_size=1.0-num_train, shuffle=True)\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X_train_70), (batch_size,))\n",
    "    feats_train_batch = X_train_70[batch_index]\n",
    "    Y_train_batch = y_train_70[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [np.sign(variational_classifier(weights, bias, f)) for f in X_train_70]\n",
    "    predictions_val = [np.sign(variational_classifier(weights, bias, f)) for f in X_test_30]\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_tra = accuracy(y_train_70, predictions_train)\n",
    "    acc_val = accuracy(y_test_30, predictions_val)\n",
    "    cost_train = cost(weights, bias,X_train, y_train)\n",
    "    cost_g.append(cost_train)\n",
    "    \n",
    "    acc_train.append(acc_tra)\n",
    "    acc_test.append(acc_val)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    plt.plot(cost_g,label='cost')\n",
    "    plt.plot(acc_train,label='acc_train')\n",
    "    plt.plot(acc_test,label='acc_test')\n",
    "    plt.legend(['cost','acc_train','acc_test'])\n",
    "    plt.show()\n",
    "     \n",
    "    \n",
    "    print(\n",
    "         \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "         \"\".format(it + 1, cost_train, acc_tra, acc_val)\n",
    "     )\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for x in X_test.tolist():\n",
    "    if sum(x) == 0:\n",
    "        x[0]=1\n",
    "    x_test.append( x/ np.linalg.norm(x))\n",
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = [np.sign(variational_classifier(weights, bias, f)) for f in x_test]\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "print('F1 score: %f' % f1)\n",
    " \n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_test_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_test_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "test_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(test_matrix)\n",
    "ax = sns.heatmap(test_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "ax.xaxis.set_ticklabels(['0','1'])\n",
    "ax.yaxis.set_ticklabels(['0','1'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = [int(i) for i in y_test_pred ]\n",
    "y_pred_1 = [\"{}\\n\".format(i) for i in y_pred_1]\n",
    "with open(r'mera_4_layers.csv', 'w') as fp:\n",
    "    fp.writelines(y_pred_1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "classic_BackOrders_accuracy_1_v4.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
