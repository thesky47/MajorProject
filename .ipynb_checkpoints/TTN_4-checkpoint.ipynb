{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cK5Ry9dADtir",
    "outputId": "b438ff3d-7cc8-45f8-e3db-1d436e81c1c6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpennylane\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpennylane\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NesterovMomentumOptimizer\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=False)\n",
    "\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTdT7iH2DpUG"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"dataset/fair_train.csv\")\n",
    "X_train,y_train = data_train[data_train.columns[:16]].values, data_train[data_train.columns[16]].values\n",
    "\n",
    "data_test = pd.read_csv(\"dataset/classic_test.csv\")\n",
    "X_test,y_test = data_test[data_test.columns[:16]].values, data_test[data_test.columns[16]].values\n",
    "\n",
    "(X_train.shape, y_train.shape),(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s804AwFCEFV8"
   },
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(weights, wires):\n",
    "    qml.CNOT(wires=[wires[0],wires[1]])\n",
    "    qml.RY(weights[0], wires=wires[0])\n",
    "    qml.RY(weights[1], wires=wires[1])\n",
    "\n",
    "n_wires = 4\n",
    "n_block_wires = 2\n",
    "n_params_block = 2\n",
    "n_blocks = qml.TTN.get_n_blocks(range(n_wires),n_block_wires)\n",
    "n_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2gS_r0dEN5s"
   },
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "\n",
    "    qml.AmplitudeEmbedding(x, wires=[0,1,2,3],normalize=True,pad_with=True)\n",
    "\n",
    "    for w in weights:\n",
    "\n",
    "        qml.TTN(range(n_wires),n_block_wires,block, n_params_block, w)\n",
    "        #print(w)\n",
    "    #print(x)\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLSeVH8CEPUi"
   },
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def cost(weights, bias, X, Y):\n",
    "    #print(1)\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFN174tZEU22",
    "outputId": "7de4359e-7953-487e-8f08-30a7623d639e"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "num_layers = 4\n",
    "weights_init = 2*np.pi * np.random.randn(num_layers,n_blocks, n_params_block, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(qml.draw(circuit,expansion_strategy='device',wire_order=[0,1,2,3])(weights_init,np.asarray(X_train[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2IhcVFlEV_V",
    "outputId": "3b78e6fc-f121-4095-a4b3-47e1b07ce621"
   },
   "outputs": [],
   "source": [
    "for i in weights_init:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WEWkuIOEXnm"
   },
   "outputs": [],
   "source": [
    "y_train = np.where(y_train < 1, -1, y_train)\n",
    "y_test = np.where(y_test < 1, -1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vrs1X5UiMnWJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X,y = shuffle(X_train, y_train, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8Z8HLOXEY1n",
    "outputId": "249d3445-bac4-4885-8c86-49053fd8b78a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "opt = NesterovMomentumOptimizer(0.4)\n",
    "batch_size = 32\n",
    "\n",
    "num_data = len(y_train)\n",
    "num_train = 0.9\n",
    "# train the variational classifier\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "print()\n",
    "\n",
    "cost_g = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "plt.show()\n",
    "for it in range(50):\n",
    "    X_train_70, X_test_30, y_train_70, y_test_30 =train_test_split(np.asarray(X), np.asarray(y), train_size=num_train, test_size=1.0-num_train, shuffle=True)\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X_train_70), (batch_size,))\n",
    "    feats_train_batch = X_train_70[batch_index]\n",
    "    Y_train_batch = y_train_70[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    predictions_train = [np.sign(variational_classifier(weights, bias, f)) for f in X_train_70]\n",
    "    predictions_val = [np.sign(variational_classifier(weights, bias, f)) for f in X_test_30]\n",
    "    # Compute accuracy on train and validation set\n",
    "    acc_tra = accuracy(y_train_70, predictions_train)\n",
    "    acc_val = accuracy(y_test_30, predictions_val)\n",
    "    cost_train = cost(weights, bias,X_train, y_train)\n",
    "    cost_g.append(cost_train)\n",
    "    \n",
    "    acc_train.append(acc_tra)\n",
    "    acc_test.append(acc_val)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    plt.plot(cost_g,label='cost')\n",
    "    plt.plot(acc_train,label='acc_train')\n",
    "    plt.plot(acc_test,label='acc_test')\n",
    "    plt.legend(['cost','acc_train','acc_test'])\n",
    "    plt.show()\n",
    "     \n",
    "    \n",
    "    print(\n",
    "         \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "         \"\".format(it + 1, cost_train, acc_tra, acc_val)\n",
    "     )\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for x in X_test.tolist():\n",
    "    x[0]+=1\n",
    "    x_test.append( x/ np.linalg.norm(x))\n",
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = [np.sign(variational_classifier(weights, bias, f)) for f in x_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "print('F1 score: %f' % f1)\n",
    " \n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_test_pred)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, y_test_pred)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "test_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(test_matrix)\n",
    "ax = sns.heatmap(test_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "ax.xaxis.set_ticklabels(['0','1'])\n",
    "ax.yaxis.set_ticklabels(['0','1'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = [int(i) for i in y_test_pred ]\n",
    "y_pred_1 = [\"{}\\n\".format(i) for i in y_pred_1]\n",
    "with open(r'ttn_4_layers.csv', 'w') as fp:\n",
    "    fp.writelines(y_pred_1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "classic_BackOrders_accuracy_1_v4.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
